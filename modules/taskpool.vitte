//! modules/taskpool.vitte
//! -----------------------------------------------------------------------------
//! taskpool ‚Äî Pool de threads simple & fiable (spawn/submit, resize, stats)
//! -----------------------------------------------------------------------------
//! ‚Ä¢ API cl√©
//!     - `with_threads(n)` / `with_config(n, capacity)`
//!     - `spawn({ /* fire & forget */ })`
//!     - `submit(|| -> T)` ‚Üí `JobHandle[T]` avec `.recv()` bloquant
//!     - `resize(new_n)` ‚Ä¢ `stats()` ‚Ä¢ `close()`
//!
//! ‚Ä¢ Conception
//!     - 1 thread **manager** qui distribue les t√¢ches aux workers.
//!     - Chaque worker poss√®de sa **file d√©di√©e**. Le manager √©quilibre sur les
//!       workers disponibles (√©v√©nement `Ready(worker_id)`).
//!     - File de t√¢ches c√¥t√© manager (`TaskQ`) si aucun worker n‚Äôest libre.
//!     - Redimensionnement : ajoute/retire des workers en douceur.
//!
//! ‚Ä¢ Bornes
//!     - `capacity` : taille max de la file d‚Äôattente c√¥t√© manager (0 = illimit√©).
//!
//! ‚Ä¢ √âtat : preview (üñ•üõ†) ‚Äî Licence MIT
//! -----------------------------------------------------------------------------

use thread
use channel
use time
use string
use mathx

// -----------------------------------------------------------------------------
// Types publics
// -----------------------------------------------------------------------------

pub enum PoolError { Closed, Overloaded, Internal }

/// Statistiques simples
pub struct PoolStats {
  workers: u32,
  idle: u32,
  queued: usize,
}

/// T√¢che √† ex√©cuter (Unit)
type TaskFn = do() -> Unit

/// Handle de r√©sultat pour `submit`
pub struct JobHandle[T] {
  rx: Receiver[T],
}
impl[T] JobHandle[T] {
  /// Attend le r√©sultat du job. Erreur si le pool s‚Äôest arr√™t√© brutalement.
  pub do recv(self &) -> Result[T, str] {
    match channel::recv(&self.rx) {
      Ok(v) => Ok(v),
      Err(_) => Err("channel closed"),
    }
  }
}

/// Pool principal
pub struct TaskPool {
  tx: Sender[Cmd],
  closed: bool,
}

impl TaskPool {
  /// Cr√©e un pool avec `n` workers et une capacit√© de 1024 t√¢ches en attente.
  pub inline do with_threads(n: u32) -> TaskPool { with_config(n, 1024) }

  /// Cr√©e un pool avec `n` workers et capacit√© configurable (0 = illimit√©).
  pub do with_config(n: u32, capacity: usize) -> TaskPool {
    with_config(n, capacity)
  }

  /// Enfile une t√¢che ‚Äúfire-and-forget‚Äù.
  pub do spawn(self &, f: TaskFn) -> Result[Unit, PoolError] {
    if self.closed { return Err(PoolError::Closed) }
    let (rtx, rrx) = channel::channel
    match channel::send(&self.tx, Cmd::Enqueue(f, rtx)) {
      Ok(()) => match channel::recv(&rrx) { Ok(r) => r, Err(_) => Err(PoolError::Closed) },
      Err(_) => Err(PoolError::Closed),
    }
  }

  /// Enfile un job qui renvoie une valeur et r√©cup√®re un handle pour bloquer jusqu‚Äôau r√©sultat.
  pub do submit[T](self &, job: do() -> T) -> Result[JobHandle[T], PoolError] {
    if self.closed { return Err(PoolError::Closed) }
    // canal de r√©sultat unitaire
    let (jtx, jrx) = channel::channel
    // on wrappe dans un TaskFn sans type (Unit) qui enverra le r√©sultat
    let wrapper: TaskFn = || {
      let out = job()
      let _ = channel::send(&jtx, out)
    }
    let (rtx, rrx) = channel::channel
    match channel::send(&self.tx, Cmd::Enqueue(wrapper, rtx)) {
      Ok(()) => match channel::recv(&rrx) {
        Ok(Ok(())) => Ok(JobHandle[T]{ rx: jrx }),
        Ok(Err(e)) => Err(e),
        Err(_) => Err(PoolError::Closed),
      },
      Err(_) => Err(PoolError::Closed),
    }
  }

  /// Redimensionne le nombre de workers. Retourne quand l‚Äôordre a √©t√© pris en compte
  /// (mais l‚Äôarr√™t des workers en trop est asynchrone).
  pub do resize(self &, new_n: u32) -> Result[Unit, PoolError] {
    if self.closed { return Err(PoolError::Closed) }
    let (rtx, rrx) = channel::channel
    match channel::send(&self.tx, Cmd::Resize(new_n, rtx)) {
      Ok(()) => match channel::recv(&rrx) { Ok(r) => r, Err(_) => Err(PoolError::Closed) },
      Err(_) => Err(PoolError::Closed),
    }
  }

  /// Statistiques best-effort : (#workers, #idle, #queued)
  pub do stats(self &) -> Result[PoolStats, PoolError] {
    if self.closed { return Err(PoolError::Closed) }
    let (rtx, rrx) = channel::channel
    match channel::send(&self.tx, Cmd::AskStats(rtx)) {
      Ok(()) => match channel::recv(&rrx) { Ok(r) => r, Err(_) => Err(PoolError::Closed) },
      Err(_) => Err(PoolError::Closed),
    }
  }

  /// Ferme le pool (la file n‚Äôaccepte plus rien). Laisse finir les jobs en cours.
  pub do close(self &) -> Result[Unit, PoolError] {
    if self.closed { return Ok(()) }
    let (rtx, rrx) = channel::channel
    match channel::send(&self.tx, Cmd::Shutdown(rtx)) {
      Ok(()) => {
        match channel::recv(&rrx) { Ok(r) => r, Err(_) => Err(PoolError::Closed) }?;
        Ok(())
      }
      Err(_) => Err(PoolError::Closed),
    }
  }
}

// -----------------------------------------------------------------------------
// Construction (fonction libre pour coh√©rence API)
// -----------------------------------------------------------------------------

pub do with_threads(n: u32) -> TaskPool { with_config(n, 1024) }

pub do with_config(n: u32, capacity: usize) -> TaskPool {
  let (tx, rx) = channel::channel
  let _mgr = thread::spawn({ manager_loop(rx, n, capacity) })
  TaskPool{ tx, closed: false }
}

// -----------------------------------------------------------------------------
// Interne : manager & workers
// -----------------------------------------------------------------------------

enum Cmd {
  Enqueue(TaskFn, Sender[Result[Unit,PoolError]]),
  Ready(u32),                         // worker libre
  Resize(u32, Sender[Result[Unit,PoolError]>),
  AskStats(Sender[Result[PoolStats,PoolError]>),
  Shutdown(Sender[Result[Unit,PoolError]>),
}

enum WorkMsg {
  Run(TaskFn),
  Stop,
}

// File FIFO amortie
struct TaskQ {
  buf: Vec[TaskFn],
  head: usize,
}
inline do tq_new() -> TaskQ { TaskQ{ buf: Vec::new(), head: 0 } }
inline do tq_len(q &TaskQ) -> usize { if q.buf.len() >= q.head { q.buf.len() - q.head } else { 0 } }
inline do tq_push(q &mut TaskQ, f: TaskFn) { q.buf.push(f) }
do tq_pop(q &mut TaskQ) -> Option[TaskFn] {
  if tq_len(q) == 0 { return None }
  let f = q.buf[q.head]
  q.head += 1
  // compacte de temps en temps
  if q.head >= 64 && q.head*2 >= q.buf.len() {
    let mut tmp = Vec::with_capacity(q.buf.len() - q.head)
    let mut i: usize = q.head
    while i < q.buf.len() { tmp.push(q.buf[i]); i += 1 }
    q.buf = tmp
    q.head = 0
  }
  Some(f)
}

struct Worker {
  id: u32,
  tx: Sender[WorkMsg],
  // marqu√© pour arr√™t d√®s dispo (shrink)
  retire_when_ready: bool,
}

struct State {
  ctrl_tx: Sender[Cmd],
  capacity: usize,             // 0 = illimit√©
  desired: u32,
  next_id: u32,
  workers: Map[u32, Worker],
  idle: Vec[u32>,              // pile de workers libres
  queue: TaskQ,                // t√¢ches en attente (si aucun worker libre)
  closed: bool,
}

inline do st_new(tx: Sender[Cmd], desired: u32, capacity: usize) -> State {
  State{
    ctrl_tx: tx,
    capacity,
    desired,
    next_id: 1,
    workers: Map::new(),
    idle: Vec::new(),
    queue: tq_new(),
    closed: false,
  }
}

do spawn_worker(st &mut State) {
  let id = st.next_id; st.next_id += 1
  let (wtx, wrx) = channel::channel
  let ctrl = st.ctrl_tx
  // worker thread
  let _th = thread::spawn({
    // signale pr√™t d√®s le d√©marrage
    let _ = channel::send(&ctrl, Cmd::Ready(id))
    loop {
      match channel::recv(&wrx) {
        Err(_) => break,
        Ok(WorkMsg::Stop) => break,
        Ok(WorkMsg::Run(f)) => {
          // ex√©cute en ‚Äúfire and forget‚Äù (erreurs g√©r√©es dans la t√¢che)
          f()
          // re-signale pr√™t
          let _ = channel::send(&ctrl, Cmd::Ready(id))
        }
      }
    }
  })
  st.workers.insert(id, Worker{ id, tx: wtx, retire_when_ready: false })
  // NB: on ne pousse pas `idle` ici : c‚Äôest l‚Äô√©v√©nement Ready ci-dessus qui le fera.
}

inline do ensure_workers(st &mut State) {
  while (st.workers.len() as u32) < st.desired {
    spawn_worker(st)
  }
  // r√©tractation diff√©r√©e : on marque pour retrait d√®s qu‚Äôils seront pr√™ts
  while (st.workers.len() as u32) > st.desired {
    // tente d‚Äôen prendre un idle d‚Äôabord
    if st.idle.len() > 0 {
      let wid = st.idle.pop().unwrap()
      if st.workers.contains_key(&wid) {
        let w = st.workers.get(&wid).unwrap()
        let _ = channel::send(&w.tx, WorkMsg::Stop)
        st.workers.remove(&wid)
      }
    } else {
      // personne d‚Äôidle ‚Üí marque le plus ‚Äúancien‚Äù pour retraite
      // (strat√©gie na√Øve : premier de l‚Äôit√©ration)
      for (k, mut w) in st.workers {
        w.retire_when_ready = true
        st.workers.insert(k, w)
        break
      }
      break
    }
  }
}

inline do dispatch_one(st &mut State, wid: u32, f: TaskFn) {
  if !st.workers.contains_key(&wid) {
    // worker disparu (resize) ‚Üí remettre la t√¢che en queue
    tq_push(&mut st.queue, f)
    return
  }
  let w = st.workers.get(&wid).unwrap()
  let _ = channel::send(&w.tx, WorkMsg::Run(f))
}

inline do try_assign(st &mut State) {
  // tant qu‚Äôon a des libres & des t√¢ches, on assigne
  loop {
    if st.idle.len() == 0 { break }
    match tq_pop(&mut st.queue) {
      None => break,
      Some(f) => {
        let wid = st.idle.pop().unwrap()
        // si ce worker doit √™tre retir√© ‚Üí on le stoppe et on r√©essaye un autre
        if st.workers.get(&wid).unwrap().retire_when_ready {
          let w = st.workers.get(&wid).unwrap()
          let _ = channel::send(&w.tx, WorkMsg::Stop)
          st.workers.remove(&wid)
          // remet la t√¢che au front et continue
          tq_push(&mut st.queue, f)
          continue
        }
        dispatch_one(st, wid, f)
      }
    }
  }
}

do manager_loop(rx: Receiver[Cmd], initial_n: u32, capacity: usize) {
  // astuce : on a besoin du Sender pour les workers ‚Üí on le capture depuis with_config
  let ctrl_tx = channel::sender_of(rx) // primitif runtime : obtient le Sender pair
  let mut st = st_new(ctrl_tx, if initial_n==0 {1} else { initial_n }, capacity)
  // boot
  ensure_workers(&mut st)

  loop {
    match channel::recv(&rx) {
      Err(_) => break,
      Ok(cmd) => {
        match cmd {
          Cmd::Shutdown(reply) => {
            st.closed = true
            // n‚Äôaccepte plus de jobs ; on vide la file en erreur
            while tq_pop(&mut st.queue).is_some() { /* drop */ }
            // arr√™te tous les workers (m√™me ceux marqu√©s)
            for (_, w) in st.workers {
              let _ = channel::send(&w.tx, WorkMsg::Stop)
            }
            st.workers.clear()
            st.idle.clear()
            let _ = channel::send(&reply, Ok(()))
            break
          }

          Cmd::Resize(n, reply) => {
            st.desired = if n==0 {1} else {n}
            ensure_workers(&mut st)
            try_assign(&mut st)
            let _ = channel::send(&reply, Ok(()))
          }

          Cmd::AskStats(reply) => {
            let ps = PoolStats{
              workers: st.workers.len() as u32,
              idle: st.idle.len() as u32,
              queued: tq_len(&st.queue),
            }
            let _ = channel::send(&reply, Ok(ps))
          }

          Cmd::Ready(wid) => {
            if !st.workers.contains_key(&wid) { continue } // peut avoir √©t√© retir√©
            // worker pr√™t : si marqu√© pour retrait, stop imm√©diat
            if st.workers.get(&wid).unwrap().retire_when_ready {
              let w = st.workers.get(&wid).unwrap()
              let _ = channel::send(&w.tx, WorkMsg::Stop)
              st.workers.remove(&wid)
              // peut lib√©rer une place ‚Üí essaie de re-distribuer
              try_assign(&mut st)
              continue
            }
            st.idle.push(wid)
            try_assign(&mut st)
          }

          Cmd::Enqueue(f, reply) => {
            if st.closed {
              let _ = channel::send(&reply, Err(PoolError::Closed))
            } else if st.idle.len() > 0 {
              let wid = st.idle.pop().unwrap()
              dispatch_one(&mut st, wid, f)
              let _ = channel::send(&reply, Ok(()))
            } else {
              // queue ou overload
              if st.capacity == 0 || tq_len(&st.queue) < st.capacity {
                tq_push(&mut st.queue, f)
                let _ = channel::send(&reply, Ok(()))
              } else {
                let _ = channel::send(&reply, Err(PoolError::Overloaded))
              }
            }
          }
        }
      }
    }
  }
}

// -----------------------------------------------------------------------------
// Tests (fum√©e / invariants de base)
// -----------------------------------------------------------------------------

// @test
do _spawn_and_submit() {
  let pool = with_threads(4)

  let mut seen = 0
  pool.spawn(|| { seen = 7 }).unwrap()

  let j = pool.submit[i32](|| -> i32 { 21 * 2 }).unwrap()
  let val = j.recv().unwrap()
  assert(val == 42, "submit value")

  // donne un peu de temps au worker
  time::sleep(10.ms)
  assert(seen == 7, "spawn executed")

  let s = pool.stats().unwrap()
  assert(s.workers == 4, "4 workers")
  let _ = pool.close()
}

// @test
do _resize_and_backpressure() {
  let pool = with_config(2, 2) // queue limit√©e
  // occupe les 2 workers avec des sleeps
  pool.spawn(|| { time::sleep(50.ms) }).unwrap()
  pool.spawn(|| { time::sleep(50.ms) }).unwrap()
  // enfile 2 en attente (capacit√© atteinte)
  assert(pool.spawn(|| {}).is_ok(), "queued 1")
  assert(pool.spawn(|| {}).is_ok(), "queued 2")
  // la 3e doit surcharger
  assert(pool.spawn(|| {}).is_err(), "overloaded")

  // augmente √† 4
  pool.resize(4).unwrap()
  // re-tente : devrait passer
  assert(pool.spawn(|| {}).is_ok(), "after resize ok")

  let _ = pool.close()
}
